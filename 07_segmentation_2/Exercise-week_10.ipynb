{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e71b7c7-241f-421f-9933-fb4789ce2126",
   "metadata": {},
   "source": [
    "# Exercises for Week 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed407dde-80f8-4a03-bccf-47337aa612fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib notebook \n",
    "#try widget instead if graphs aren't showing\n",
    "\n",
    "import cv2\n",
    "import maxflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import ipywidgets as widgets\n",
    "from matplotlib.patches import Circle\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5cdbb-e3da-46d0-a4ff-45cb2036535c",
   "metadata": {},
   "source": [
    "## Hair removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82153916-4d5e-4082-b86d-4867ae1b14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is the pseudo code\n",
    "# def removeHair(img_org, img_gray, kernel_size=25, threshold=10, radius=3):\n",
    "#     # kernel for the morphological filtering\n",
    "#     kernel ← cv2.getStructuringElement(***)\n",
    "    \n",
    "#     # perform the hat transform on the grayscale image\n",
    "#     hat_img ← cv2.morphologyEx(***)\n",
    "    \n",
    "#     # threshold the hair contours\n",
    "#     _, thresh ← cv2.threshold(***)\n",
    "    \n",
    "#     # inpaint the original image depending on the mask\n",
    "#     img_out = cv2.inpaint(img_org, thresh, radius, cv2.INPAINT_TELEA)\n",
    "    \n",
    "#     return hat_img, thresh, img_out\n",
    "    \n",
    "\n",
    "def removeHair(img_org, img_gray, kernel_size=25, threshold=10, radius=3):\n",
    "    \n",
    "    ### Your code here ###\n",
    "    \n",
    "    return hat_img, thresh, img_out\n",
    "\n",
    "# read the image file (test both sample_001 and sample_002)\n",
    "file_path = './sample_001.jpg'\n",
    "img_bgr = cv2.imread(file_path)\n",
    "\n",
    "# resize the image\n",
    "max_size = 256\n",
    "h, w = img_bgr.shape[:2]\n",
    "scale = min(max_size / w, max_size / h)\n",
    "if scale < 1:\n",
    "    new_size = (int(w * scale), int(h * scale))\n",
    "    img_bgr = cv2.resize(img_bgr, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# permute color channels and convert to grayscale\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# apply hair removal; note: kernel_size and threshold can be adjusted as needed\n",
    "blackhat, thresh, img_out = removeHair(img_rgb, img_gray, kernel_size=7, threshold=10)\n",
    "\n",
    "# plot the images\n",
    "plt.figure()\n",
    "\n",
    "# original image\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# hat-transformed image\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(blackhat, cmap=\"gray\")\n",
    "plt.title(\"BlackHat Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# thresholded mask\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(thresh, cmap=\"gray\")\n",
    "plt.title(\"Thresholded Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# inpainted image\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(img_out)\n",
    "plt.title(\"Inpainted Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530967a-9d17-4110-a28b-ddec67315557",
   "metadata": {},
   "source": [
    "## Region growing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab0edf-f0de-408c-9bf2-e2cb78022fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the pseudo code\n",
    "# def regionGrowing(image, seed, threshold):\n",
    "#     h, w = image.shape\n",
    "#     mask = np.zeros((h, w), dtype=bool)\n",
    "#     region_pixels = []\n",
    "#     stack = [seed]\n",
    "    \n",
    "#     # initialize the region's intensity mean with the seed value\n",
    "#     region_mean = float(image[seed])\n",
    "#     count = 1\n",
    "    \n",
    "#     mask[seed] = True\n",
    "#     region_pixels.append(seed)\n",
    "    \n",
    "#     # 4-connected neighbors: up, down, left, right\n",
    "#     neighbors = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "\n",
    "#     // Process the pixels in the stack until it is empty\n",
    "#     WHILE stack is not empty:\n",
    "#         // Remove the last pixel from the stack (current pixel)\n",
    "#         (x, y) ← remove and return last element from stack\n",
    "\n",
    "#         // For each neighbor direction:\n",
    "#         FOR each (dx, dy) in neighbors:\n",
    "#             nx ← x + dx\n",
    "#             ny ← y + dy\n",
    "\n",
    "#             // Check if the neighbor pixel (nx, ny) is inside the image bounds and not already in the region\n",
    "#             IF (nx is within 0 and h-1) AND (ny is within 0 and w-1) AND (mask[nx, ny] is 0):\n",
    "#                 pixel_val ← intensity of image at (nx, ny)\n",
    "\n",
    "#                 // Check if the neighbor's intensity is within the threshold of the current region mean\n",
    "#                 IF absolute(pixel_val - region_mean) ≤ threshold:\n",
    "#                     // Include the neighbor pixel in the region\n",
    "#                     mask[nx, ny] ← TRUE\n",
    "#                     Add (nx, ny) to stack\n",
    "#                     Add (nx, ny) to region_pixels\n",
    "\n",
    "#                     // Update the region's mean intensity to include the new pixel\n",
    "#                     region_mean ← (region_mean * count + pixel_val) / (count + 1)\n",
    "#                     count ← count + 1\n",
    "\n",
    "#     return mask\n",
    "                        \n",
    "def regionGrowing(image, seed, threshold):\n",
    "\n",
    "    ### Your code here ###\n",
    "                    \n",
    "    return mask\n",
    "\n",
    "# we need a grayscale version of img_out.\n",
    "gray_img_out = cv2.cvtColor(img_out, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find the darkest pixel\n",
    "min_index = np.unravel_index(np.argmin(gray_img_out), gray_img_out.shape)\n",
    "\n",
    "# apply region growing segmentation using the darkest pixel as the seed\n",
    "segmentation_mask = regionGrowing(gray_img_out, min_index, threshold=40)\n",
    "\n",
    "# plot the original grayscale image and the segmentation mask\n",
    "plt.figure()\n",
    "\n",
    "# grayscale image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray_img_out, cmap='gray')\n",
    "plt.title(\"Grayscale Inpainted Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# segmentation mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(segmentation_mask, cmap='gray')\n",
    "plt.title(\"Region Growing Segmentation\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafcdcea-ce55-4493-a519-65db1c0daa06",
   "metadata": {},
   "source": [
    "## Watershed algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3920ee-a777-4db7-a994-674f459d3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is the code with missing lines\n",
    "# def watershedAlgorithm(gray_img, kernel_size=3, opening_iter=2, dilation_iter=3, dt_thresh=0.5):\n",
    "#     # apply Otsu's thresholding (with inversion) to obtain a binary image\n",
    "#     ret, thresh = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "#     # remove noise with morphological opening\n",
    "#     kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "#     opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=opening_iter)\n",
    "    \n",
    "#     # dilate to obtain sure background regions\n",
    "#     sure_bg = cv2.dilate(opening, kernel, iterations=dilation_iter)\n",
    "    \n",
    "#     # use distance transform to get sure foreground regions\n",
    "#     dist_transform ← cv2.distanceTransform(opening, ***)\n",
    "#     ret, sure_fg = cv2.threshold(dist_transform, dt_thresh * dist_transform.max(), 255, 0)\n",
    "#     sure_fg = np.uint8(sure_fg)\n",
    "    \n",
    "#     # the unknown region is the difference between sure background and sure foreground\n",
    "#     unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "#     # marker labeling\n",
    "#     ret, markers = cv2.connectedComponents(sure_fg)\n",
    "#     markers = markers + 1\n",
    "#     markers[unknown == 255] = 0   \n",
    "    \n",
    "#     # apply watershed algorithm\n",
    "#     img_color = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2BGR)\n",
    "#     markers ← cv2.watershed(***)\n",
    "    \n",
    "#     # mark the watershed boundaries in green (where marker == -1)\n",
    "#     img_color[markers == -1] = [0, 255, 0]\n",
    "    \n",
    "#     return markers, img_color\n",
    "\n",
    "def watershedAlgorithm(gray_img, kernel_size=3, opening_iter=2, dilation_iter=3, dt_thresh=0.5):\n",
    "    \n",
    "    ### Your code here ###\n",
    "    \n",
    "    return markers, img_color\n",
    "\n",
    "# apply watershed algorithm:\n",
    "markers, segmented_img = watershedAlgorithm(gray_img_out)\n",
    "\n",
    "# plot the original grayscale image and the watershed segmentation result\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(gray_img_out, cmap='gray')\n",
    "plt.title(\"Grayscale Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(segmented_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Watershed Segmentation\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a914e7-b28d-4bc0-98be-2e3305964d23",
   "metadata": {},
   "source": [
    "## Graph-cut\n",
    "### If it doesn't work, downgrade jupyter by: pip install \"notebook<7\"\n",
    "### Also run: pip install ipympl opencv-python ipywidgets PyMaxflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ea1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphcut(image, scribble_mask, lambda_val=50, sigma=10):\n",
    "    H, W, _ = image.shape\n",
    "    img = image.astype(np.float64)\n",
    "    \n",
    "    # identify scribbled regions\n",
    "    fg_pixels = scribble_mask == 1  # definite foreground\n",
    "    bg_pixels = scribble_mask == 2  # definite background\n",
    "    \n",
    "    # compute mean colors for scribbled foreground and background\n",
    "    fg_mean = np.mean(img[fg_pixels], axis=0) if np.any(fg_pixels) else np.zeros(3)\n",
    "    bg_mean = np.mean(img[bg_pixels], axis=0) if np.any(bg_pixels) else np.zeros(3)\n",
    "    \n",
    "    # data costs based on squared color distances\n",
    "    data_cost_fg = np.sum((img - fg_mean)**2, axis=2)\n",
    "    data_cost_bg = np.sum((img - bg_mean)**2, axis=2)\n",
    "    \n",
    "    # normalize the data costs\n",
    "    data_cost_fg = data_cost_fg / (np.max(data_cost_fg) + 1e-8)\n",
    "    data_cost_bg = data_cost_bg / (np.max(data_cost_bg) + 1e-8)\n",
    "    \n",
    "    # build the graph\n",
    "    g = maxflow.Graph[float]()\n",
    "    nodeids = g.add_grid_nodes((H, W))\n",
    "    \n",
    "    # terminal (data) capacities\n",
    "    source_cap = data_cost_fg.copy()\n",
    "    sink_cap = data_cost_bg.copy()\n",
    "    \n",
    "    # for scribbled pixels, force the label\n",
    "    source_cap[scribble_mask == 1] = 0      # Force foreground.\n",
    "    sink_cap[scribble_mask == 1] = 1e9\n",
    "    source_cap[scribble_mask == 2] = 1e9      # Force background.\n",
    "    sink_cap[scribble_mask == 2] = 0\n",
    "    \n",
    "    g.add_grid_tedges(nodeids, source_cap, sink_cap)\n",
    "    \n",
    "    # add smoothness (neighborhood) terms\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if j < W - 1:\n",
    "                diff = np.linalg.norm(img[i, j] - img[i, j+1])\n",
    "                weight = lambda_val * np.exp(- (diff**2) / (2 * sigma**2))\n",
    "                g.add_edge(nodeids[i, j], nodeids[i, j+1], weight, weight)\n",
    "                \n",
    "            if i < H - 1:\n",
    "                diff = np.linalg.norm(img[i, j] - img[i+1, j])\n",
    "                weight = lambda_val * np.exp(- (diff**2) / (2 * sigma**2))\n",
    "                g.add_edge(nodeids[i, j], nodeids[i+1, j], weight, weight)\n",
    "                \n",
    "    # compute the min-cut\n",
    "    g.maxflow()\n",
    "    seg_mask = np.zeros((H, W), dtype=bool)\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            seg_mask[i, j] = True if g.get_segment(nodeids[i, j]) == 0 else False\n",
    "            \n",
    "    return seg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7b367-6293-455d-b93d-f8c6c4ca360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'path_to_image.jpg' with the path to your image.\n",
    "image_path = './example.jpg'\n",
    "image_bgr = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# below are some codes and functions irrelevant to graph-cut\n",
    "def on_press(event):\n",
    "    global dragging\n",
    "    if event.inaxes != ax:\n",
    "        return\n",
    "    dragging = True\n",
    "    draw_at(event.xdata, event.ydata)\n",
    "\n",
    "def on_motion(event):\n",
    "    if dragging and event.inaxes == ax:\n",
    "        draw_at(event.xdata, event.ydata)\n",
    "        \n",
    "def on_release(event):\n",
    "    global dragging\n",
    "    dragging = False\n",
    "    \n",
    "def on_mode_change(change):\n",
    "    global current_mode\n",
    "    current_mode = change['new']\n",
    "\n",
    "def on_segment_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Running Graph-Cut segmentation...\")\n",
    "    seg_mask = graphcut(image, scribble_mask)\n",
    "    \n",
    "    result_color = np.zeros_like(image)\n",
    "    result_color[~seg_mask] = image[~seg_mask]\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(6, 6))\n",
    "    ax2.imshow(result_color)\n",
    "    ax2.set_title(\"Graph-Cut Segmentation (Color)\")\n",
    "    ax2.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_at(xdata, ydata):\n",
    "    global scribble_mask, overlay_data, scribble_points\n",
    "    x, y = int(xdata), int(ydata)\n",
    "    if current_mode == 'foreground':\n",
    "        color = (255, 0, 0)\n",
    "        mask_value = 1\n",
    "    else:\n",
    "        color = (0, 0, 255)\n",
    "        mask_value = 2\n",
    "\n",
    "    cv2.circle(scribble_mask, (x, y), brush_radius, mask_value, -1)\n",
    "    cv2.circle(overlay_data, (x, y), brush_radius, color, -1)\n",
    "    scribble_points.append((x, y, brush_radius, color))\n",
    "    overlay_image.set_data(overlay_data)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "scribble_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "brush_radius = 5\n",
    "current_mode = 'foreground'\n",
    "overlay_data = np.zeros_like(image, dtype=np.uint8)\n",
    "scribble_points = []\n",
    "dragging = False\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.imshow(image)\n",
    "overlay_image = ax.imshow(overlay_data, alpha=0.5)\n",
    "ax.set_title(\"Drag to scribble: red=FG, blue=BG\")\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', on_press)\n",
    "fig.canvas.mpl_connect('motion_notify_event', on_motion)\n",
    "fig.canvas.mpl_connect('button_release_event', on_release)\n",
    "\n",
    "mode_selector = widgets.ToggleButtons(\n",
    "    options=[('Foreground', 'foreground'), ('Background', 'background')],\n",
    "    description='Mode:'\n",
    ")\n",
    "\n",
    "mode_selector.observe(on_mode_change, names='value')\n",
    "display(mode_selector)\n",
    "\n",
    "segmentation_button = widgets.Button(description=\"Run Graph-Cut\")\n",
    "output = widgets.Output()\n",
    "\n",
    "segmentation_button.on_click(on_segment_clicked)\n",
    "display(segmentation_button, output)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
