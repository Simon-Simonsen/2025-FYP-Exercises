{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LiXFkf1a-Iy"
      },
      "source": [
        "## Exercises classifiers and evaluation\n",
        "\n",
        "These exercises follow the general setup of [this tutorial in the R language](https://compgenomr.github.io/book/model-tuning-and-avoiding-overfitting.html).\n",
        "\n",
        "In this exercise session you will go through some concepts related to classifiers and evaluation in Python. Parts of the code are already implemented, you need to fill in the remaining parts.\n",
        "\n",
        "Your code should produce figures similar to the ones in the tutorial, but because the data you use is different, you will not get the same values.\n",
        "\n",
        "If you want to see whether you get the same plots for the tutorial's data, check earlier chapters of the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm2YM2gzK1FX"
      },
      "source": [
        "## Load all the things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMTSVdgIOM4K",
        "outputId": "ca701be0-2566-43e7-ca4c-349a8ca6b665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fyp2022-imaging'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Total 325 (delta 0), reused 0 (delta 0), pack-reused 325 (from 1)\u001b[K\n",
            "Receiving objects: 100% (325/325), 825.97 MiB | 26.69 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "Updating files: 100% (309/309), done.\n",
            "   melanoma      area  perimeter\n",
            "0       0.0  216160.0     2013.0\n",
            "1       0.0  130493.0     1372.0\n",
            "2       0.0  205116.0     1720.0\n",
            "3       0.0  161705.0     1344.0\n",
            "4       0.0  317040.0     2063.0\n"
          ]
        }
      ],
      "source": [
        "# Packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Clone repository with example images\n",
        "!rm -rf fyp2022-imaging\n",
        "!git clone https://github.com/vcheplygina/fyp2022-imaging.git\n",
        "\n",
        "\n",
        "# Load features and labels\n",
        "file_data = 'fyp2022-imaging/data/example_ground_truth.csv'\n",
        "file_features = 'fyp2022-imaging/features/features.csv'\n",
        "\n",
        "df = pd.read_csv(file_data)\n",
        "features = pd.read_csv(file_features)\n",
        "\n",
        "\n",
        "# Combine variables we want in one place\n",
        "df = df.drop(['image_id','seborrheic_keratosis'],axis=1)\n",
        "df['area'] = features['area']\n",
        "df['perimeter'] = features['perimeter']\n",
        "\n",
        "# Please remember that area and perimeter alone are often not sufficient for classification.\n",
        "# When doing your project, you could also try the other features here.\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF8WkV2scMEP"
      },
      "outputs": [],
      "source": [
        "# Prepare development (train and validation) and test splits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df[['area','perimeter']]\n",
        "y = df[['melanoma']]\n",
        "\n",
        "dev_x, test_x, dev_y, test_y = train_test_split(\n",
        "        x, y, stratify=y, random_state=0)\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(\n",
        "        dev_x, dev_y, stratify=dev_y)\n",
        "\n",
        "\n",
        "## TODOs for students\n",
        "\n",
        "# For reducing computation, you may want to reduce the size of the selected data using train_size and test_size parameters.\n",
        "# However, reducing the size of the dataset will lead to more variability of your results\n",
        "\n",
        "# Think about exercises from last lecture, do we still want to do anything with the data? Do it here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV4TfOuld2iX",
        "outputId": "3257b4f8-1b6d-4a70-b7e2-ae5b6a0255de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7347826086956522\n"
          ]
        }
      ],
      "source": [
        "#Import classifier and metric\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Example of training a classifier\n",
        "knn1 = KNeighborsClassifier(n_neighbors=1) # other hyperparameters possible\n",
        "knn1_trained = knn1.fit(train_x, np.ravel(train_y))\n",
        "\n",
        "# Example of prediction\n",
        "val_pred_knn1 = knn1_trained.predict(val_x)\n",
        "val_auc_knn1 = roc_auc_score(val_y, val_pred_knn1)\n",
        "\n",
        "print(val_auc_knn1)\n",
        "\n",
        "\n",
        "# TODOs for students:\n",
        "\n",
        "# 1) Try out different parameters of K using a for loop\n",
        "\n",
        "# 2) Make a plot of the training vs validation AUC in the same plot.\n",
        "# You can also plot the accuracy metric in a different plot.\n",
        "# Remember to add proper axes labels and legend to the plots (Fig 5.5 in tutorial)\n",
        "\n",
        "# Q: Do you see the values you would expect?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reFYxRfJjgTm"
      },
      "outputs": [],
      "source": [
        "# Visualize the decision boundary\n",
        "\n",
        "# TODO for students:\n",
        "\n",
        "# Use the exercises from previous weeks to visualize the boundary of some appropriate / less appropriate choices for k (Fig 5.7 in tutorial)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zD0z_0OOacC"
      },
      "outputs": [],
      "source": [
        "# Now let's try with a different classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# TODOs for students:\n",
        "\n",
        "# 1) Investigate the max_depth parameter of the classifier, and repeat the procedure above\n",
        "\n",
        "# 2) Optionally, look at some other parameters of the classifier.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhH0WhUtkEVj"
      },
      "source": [
        "## Variance of performance depending on the split\n",
        "\n",
        "Notice the random state parameter of the classifiers. Why do we need this?\n",
        "\n",
        "You can try different choices for this parameter and investigate the effect on the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVmCZ-Auj8QV"
      },
      "outputs": [],
      "source": [
        "# TODO for students:\n",
        "\n",
        "# Choose one of the experiments above, and create the performance vs parameter plot, for two different seeds\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXkVNQ-wm8hh"
      },
      "source": [
        "1) What kind of strategies could you use to obtain more reliable performances?\n",
        "\n",
        "ANSWER:\n",
        "\n",
        "\n",
        "2) What does this tell you about the random_state, how is it different from for example a tunable k parameter?\n",
        "\n",
        "ANSWER:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFzQFdU0mG54"
      },
      "source": [
        "## Cross-validation\n",
        "\n",
        "In this part we will use cross-validation on the development set to find good k / max_depth parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jxjeWXyOZfY",
        "outputId": "87c1828e-879f-490b-91d3-b28ed74a19f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0:\n",
            "  Train: index=[ 23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40\n",
            "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
            "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
            "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
            "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111]\n",
            "  Test:  index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22]\n",
            "Fold 1:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
            "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
            "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
            "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111]\n",
            "  Test:  index=[23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
            "Fold 2:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  68  69  70  71  72  73  74  75\n",
            "  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
            "  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111]\n",
            "  Test:  index=[46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67]\n",
            "Fold 3:\n",
            "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  90  91  92  93\n",
            "  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111]\n",
            "  Test:  index=[68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]\n",
            "Fold 4:\n",
            "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]\n",
            "  Test:  index=[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Create the folds\n",
        "kfold = KFold(n_splits=5, random_state=None, shuffle=False)\n",
        "kfold.get_n_splits(dev_x, dev_y)\n",
        "\n",
        "# Check the contents of the folds\n",
        "for i, (train_index, dev_index) in enumerate(kfold.split(dev_x)):\n",
        "\n",
        "    print(f\"Fold {i}:\")\n",
        "\n",
        "    print(f\"  Train: index={train_index}\")\n",
        "\n",
        "    print(f\"  Test:  index={dev_index}\")\n",
        "\n",
        "# TODO for students:\n",
        "\n",
        "# Investigate other parameters of the KFold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyVhmbQ1rULt"
      },
      "source": [
        "## Other types of KFold\n",
        "\n",
        "In many medical imaging applications instead of KFold we need to use GroupKFold or other options in the model_selection library.\n",
        "\n",
        "**Question:**  \n",
        "\n",
        "Why might we need to use GroupKFold? Does it apply to this example data you are using? And does it apply to the PAD-UFES data? Which variable creates the groups?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ivYdOc_nlYW"
      },
      "source": [
        "## Effect of noisy features\n",
        "\n",
        "Uninformative/noisy features will affect the generalization ability of your classifiers.\n",
        "\n",
        "In this part we add uninformative (not correlated to class label) features and test (some) classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "KUpkYrQlnnAV",
        "outputId": "c6d8f2f1-96cd-40bd-844d-cc9ce24c95af"
      },
      "outputs": [],
      "source": [
        "# Generate some noisy features\n",
        "n_noisy_features = 20\n",
        "noise = np.random.RandomState(42).uniform(0, 0.1, size=(df.shape[0], n_noisy_features))\n",
        "\n",
        "# Add the noisy data to the informative features\n",
        "x_noisy = np.hstack((df[['area', 'perimeter']], noise))\n",
        "\n",
        "\n",
        "# TODO for students\n",
        "# Investigate the behavior of classifiers with regards to overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkKgkABvr4eV"
      },
      "source": [
        "## Combining everything and final evaluation\n",
        "\n",
        "The examples above give you an idea of how you can investigate the quality of different classifiers and parameters. To keep track of the results (on the development set) of the options you try, you might want to make a \"result dataset\" where you track all the classifier versions and the corresponding results. MLFlow also allows doing this, but we do not cover it in the course (but perhaps the TAs can show you)\n",
        "\n",
        "Then once you have evaluated all the options, you can select some of the better ones, retrain them, now you can use the entire development set for retraining.\n",
        "\n",
        "Your choice of these options needs to be reproducible in your project, i.e., you should not try out some classifiers/parameters and then completely remove them from your project.\n",
        "\n",
        "You can evaluate the re-trained classifiers on the so far held-out test set. Your performances (how good each classifier was) might not reflect your results on the validation set.\n",
        "\n",
        "You are NOT allowed to edit the classifiers after this point\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "KqzkRFZeOv6x",
        "outputId": "74013ec9-d72d-445e-9e57-430a361e9d52"
      },
      "outputs": [],
      "source": [
        "# TODO for students\n",
        "\n",
        "# Keep track of different classifiers/parameters with an array\n",
        "\n",
        "# Select some better ones (e.g. top 3)\n",
        "\n",
        "# Re-train\n",
        "\n",
        "# Evaluate on held-out set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdEgwrZpOyJ9"
      },
      "outputs": [],
      "source": [
        "# After this point you are not allowed to adjust the classifier, otherwise you are overfitting!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "FYP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
